{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You don't have to reload on each library update\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from methods import *\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, add\n",
    "from tensorflow.keras.layers import Layer, Dense, Dropout, Activation, Flatten, Reshape, BatchNormalization\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, UpSampling2D, ZeroPadding2D\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "from tensorflow.python.client import device_lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "        print(gpus)\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resize(name=UnnamedResize, parameters=[(Deterministic(int 360), Deterministic(int 640)), Deterministic(cubic), HW], deterministic=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|█████████████████████████████████████████████████████████████████████████████████▍                                                                                   | 3951/8000 [03:14<02:57, 22.76it/s]"
     ]
    }
   ],
   "source": [
    "augmented_imgs_path = 'D:/20.share/jaehochang/SP2Robotics/videos/'\n",
    "args = {'IMAGES': []} \n",
    "for root, dirs, files in os.walk(augmented_imgs_path):\n",
    "    for file in files:\n",
    "        args['IMAGES'].append(os.path.join(root, file))\n",
    "\n",
    "augmenters_c = {\n",
    "    'Env':{\n",
    "#         'Snowy': ia.FastSnowyLandscape(lightness_threshold=150, lightness_multiplier=2.5),\n",
    "#         'Clouds': ia.Clouds(),\n",
    "#         'Fog': ia.Fog(),\n",
    "#         'Snowflakes': ia.Snowflakes(flake_size=(0.1, 0.4), speed=(0.01, 0.05)),\n",
    "#         'Rain': ia.Rain(drop_size=(0.10, 0.20), speed=(0.1, 0.3)),\n",
    "#         'Darken': ia.Multiply(.3, per_channel=.5)\n",
    "    },\n",
    "    'Trs':{\n",
    "        'GN': ia.AdditiveGaussianNoise(loc=0, scale=(0.0, 1/10*255), per_channel=0.2),\n",
    "#         'VertFlip': ia.Flipud(),\n",
    "#         'HorizFlip': ia.HorizontalFlip(),\n",
    "#         'Rotate': ia.Rotate(rotate=(-45, 45)),\n",
    "#         'Zoom': ia.Affine(scale={\"x\": (1, 1.5), \"y\": (1, 1.5)})\n",
    "    }\n",
    "}\n",
    "\n",
    "index = 1\n",
    "frames = []\n",
    "aimgs = []\n",
    "\n",
    "factor = 10\n",
    "h, w = 9 * 4 * factor, 16 * 4 * factor\n",
    "resizer = ia.size.Resize({\"height\": h, \"width\": w})\n",
    "gray_scaler = ia.Grayscale()\n",
    "print(resizer)\n",
    "\n",
    "try:\n",
    "    pbar.close()\n",
    "except:\n",
    "    1\n",
    "    \n",
    "with tf.device('/device:GPU:0'):\n",
    "    for IMAGE in args['IMAGES'][:1]:\n",
    "        for _, augmenters in augmenters_c.items():\n",
    "            for augmenter_name, augmenter in augmenters.items():\n",
    "                cap = cv2.VideoCapture(IMAGE)\n",
    "                fourcc = cv2.VideoWriter_fourcc(*'MJPG')\n",
    "                noisy_out = cv2.VideoWriter(f\"{augmenter_name}_{IMAGE.split('/')[-1].split('.')[0]}.avi\", fourcc, 5, (w, h))\n",
    "                clean_out = cv2.VideoWriter(f\"{IMAGE.split('/')[-1].split('.')[0]}.avi\", fourcc, 5, (w, h))\n",
    "                ret, frame = cap.read()\n",
    "                d, k = 1, 8000\n",
    "                pbar = tqdm(total = d * k)\n",
    "                while ret and index < d*k:\n",
    "                    if index % d == 0:\n",
    "                        frame = resizer.augment_image(frame)\n",
    "                        frame = gray_scaler.augment_image(frame)\n",
    "                        frames.append(frame)\n",
    "                        clean_out.write(frame)\n",
    "                        \n",
    "                        aimg = aug_img(frame, augmenter)\n",
    "                        aimgs.append(aimg)\n",
    "                        noisy_out.write(aimg)\n",
    "                        \n",
    "                        pbar.update(d)\n",
    "                    index += 1\n",
    "                    ret, frame = cap.read()\n",
    "                index = 1\n",
    "                pbar.close()\n",
    "\n",
    "cap.release()\n",
    "clean_out.release()\n",
    "noisy_out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fa = np.asarray([*zip(frames, aimgs)])\n",
    "fa.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Noisy vs. Clean train image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "X_trains, X_tests = [], []\n",
    "\n",
    "X_train, X_test = model_selection.train_test_split(fa, test_size = 0.2)\n",
    "X_train, X_test = np.asarray(X_train), np.asarray(X_test)\n",
    "\n",
    "X_train = X_train.astype(\"float32\")/255.\n",
    "X_test = X_test.astype(\"float32\")/255.\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.subplot(2, 2, 2), plt.imshow(X_train[212][0])\n",
    "plt.subplot(2, 2, 1), plt.imshow(X_train[212][1])\n",
    "# plt.subplot(2, 2, 4), plt.imshow(X_train[502][0])  # train (output)\n",
    "# plt.subplot(2, 2, 3), plt.imshow(X_train[502][1])  # noisy train (input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Denoising autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/GPU:0'):\n",
    "    x = keras.layers.Input(shape=X_train[0,0].shape)\n",
    "    \n",
    "    # Encoder\n",
    "    conv1_1 = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "    conv1_1 = BatchNormalization()(conv1_1)\n",
    "    pool1 = MaxPooling2D((2, 2), padding='same')(conv1_1)\n",
    "    pool1 = BatchNormalization()(pool1)\n",
    "    conv1_2 = Conv2D(64, (3, 3), activation='relu', padding='same')(pool1)\n",
    "    conv1_2 = BatchNormalization()(conv1_2)\n",
    "    h = MaxPooling2D((2, 2), padding='same')(conv1_2)\n",
    "    h = BatchNormalization()(h)\n",
    "\n",
    "    # Decoder\n",
    "    conv2_1 = Conv2D(64, (3, 3), activation='relu', padding='same')(h)\n",
    "    conv2_1 = BatchNormalization()(conv2_1)\n",
    "    up1 = UpSampling2D((2, 2))(conv2_1)\n",
    "    up1 = BatchNormalization()(up1)\n",
    "    conv2_2 = Conv2D(64, (3, 3), activation='relu', padding='same')(up1)\n",
    "    conv2_2 = BatchNormalization()(conv2_2)\n",
    "    up2 = UpSampling2D((2, 2))(conv2_2)\n",
    "    up2 = BatchNormalization()(up2)\n",
    "    r = Conv2D(3, (3, 3), activation='linear', padding='same')(up2)\n",
    "\n",
    "    optmz = keras.optimizers.SGD()\n",
    "    loss = keras.losses.MeanSquaredError()\n",
    "    \n",
    "    autoencoder = Model(inputs=x, outputs=r)\n",
    "    autoencoder.compile(optmz, loss)\n",
    "\n",
    "    epochs = 30\n",
    "    batch_size = 4\n",
    "    \n",
    "#     print(autoencoder.summary())\n",
    "    history = autoencoder.fit(X_train[:, 1], X_train[:, 0],  # noisy train, train\n",
    "                              batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(X_test[:, 1], X_test[:, 0]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_imgs = autoencoder.predict(X_test[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 20))\n",
    "for i, j in enumerate([22]):\n",
    "    # display original\n",
    "    ax = plt.subplot(1, 2, 1)\n",
    "    plt.imshow(X_test[:, 1][j])\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    \n",
    "    # display reconstruction\n",
    "    ax = plt.subplot(1, 2, 2)\n",
    "    plt.imshow(decoded_imgs[j])\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(history.history.keys())\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jh-ip",
   "language": "python",
   "name": "jh-ip"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
